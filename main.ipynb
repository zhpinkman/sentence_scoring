{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cd7e0d5-bee9-4742-80c3-721f49e3a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc7d4778-777d-429d-a8e4-f8a444c3ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_probability(logits: torch.tensor, word_index: int) -> torch.float:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d09a3f7c-f963-43ab-a657-dada198ac7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_for_masked_sentence(sentence: str):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8825e-33ab-43cb-8b94-7abfb3e81ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e21902d-cca2-4dae-8bce-646bf6def225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6793594"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_sentence(sentence: str) -> float:\n",
    "    \n",
    "    masked_words_probs = []\n",
    "    \n",
    "    sentence_words = sentence.split()\n",
    "    for index in range(len(sentence_words)):\n",
    "        masked_word = sentence_words[index]\n",
    "        masked_sentence = (' '.join(sentence_words[:index]) + \" [MASK] \" + ' '.join(sentence_words[index + 1:])).strip()\n",
    "        \n",
    "        inputs = tokenizer(masked_sentence, return_tensors='pt')\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        \n",
    "        index = np.where(inputs.input_ids[0] == tokenizer.mask_token_id)[0][0]\n",
    "        \n",
    "        masked_word_logit = logits[0, index, tokenizer.convert_tokens_to_ids([masked_word])[0]]\n",
    "        masked_word_prob = torch.sigmoid(masked_word_logit)\n",
    "        \n",
    "        masked_words_probs.append(masked_word_prob.detach().numpy())\n",
    "        \n",
    "    return -np.sum(np.log(masked_words_probs))\n",
    "\n",
    "sentence = \"The capital of Spain is Madrid\"\n",
    "score_sentence(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
